{"cells":[{"cell_type":"code","source":["# ============================================================\n","# nb_silver_fx\n","# ------------------------------------------------------------\n","# Rôle :\n","#   - Transformer bronze_fx_raw -> silver_fx_rates\n","#   - Appliquer normalisation, typage, déduplication\n","#   - Ajouter traçabilité & audit\n","#   - Écrire la table Silver avec partitionnement mensuel\n","# ============================================================\n","\n","# ------------------------------------------------------------\n","# 0) Paramètres d'exécution (STANDARD ENTITY INTERFACE)\n","# ------------------------------------------------------------\n","# Dans Microsoft Fabric, déclarez ces paramètres dans l'UI du notebook\n","# (première cellule). Ils seront injectés comme variables Python :\n","#   - run_id\n","#   - entity_code\n","#   - load_mode\n","#   - as_of_date\n","#\n","# Defaults ci-dessous uniquement pour exécution manuelle (interactive).\n","from datetime import datetime, timezone\n","import time\n","import json\n","\n","try:\n","    run_id\n","except NameError:\n","    run_id = f\"manual-{datetime.now(timezone.utc).strftime('%Y%m%dT%H%M%SZ')}\"\n","    entity_code = \"fx_rates\"   # doit matcher ctl_entity_silver.entity_code\n","    load_mode = \"full\"         # full|incremental\n","    as_of_date = \"\"            # YYYY-MM-DD ou vide\n","\n","def _iso_utc(dt: datetime) -> str:\n","    return dt.astimezone(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n","\n","# Timing (contract v1.0)\n","_t0 = time.time()\n","_started = datetime.now(timezone.utc)\n","\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"tags":["parameters"]},"id":"c9b11813-6e0b-43c5-8164-8c9be6f565ae"},{"cell_type":"code","source":["# ------------------------------------------------------------\n","# 1) Import des utilitaires Silver\n","# ------------------------------------------------------------\n","# The command is not a standard IPython magic command. It is designed for use within Fabric notebooks only."],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ac11750f-4c73-49de-81cf-5ce53111f5af"},{"cell_type":"code","source":["%run ./nb_silver_utils"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"13c7a291-098a-4288-8248-ea484e69fbff"},{"cell_type":"code","source":["from pyspark.sql import functions as F\n","import json\n","\n","# ------------------------------------------------------------\n","# 2) Lecture de la source Bronze\n","# ------------------------------------------------------------\n","df_bronze = spark.table(\"bronze_fx_raw\")\n","\n","\n","# ------------------------------------------------------------\n","# 2bis) Filtrage incremental (OPTIONNEL) + métrique row_in (STANDARD)\n","# ------------------------------------------------------------\n","# Pour FX daily rates: incremental minimal = filtrer sur la date demandée (as_of_date)\n","# - as_of_date attendu au format YYYY-MM-DD\n","if (load_mode or \"\").strip().lower() == \"incremental\" and (as_of_date or \"\").strip():\n","    df_bronze = df_bronze.where(F.col(\"date\") == F.to_date(F.lit(as_of_date)))\n","\n","# row_in = nombre de lignes lues depuis Bronze après filtre incremental\n","row_in = df_bronze.count()\n","\n","# Contract normalization\n","as_of_date_norm = (as_of_date if (as_of_date or \"\").strip() else None)\n","\n","# ------------------------------------------------------------\n","# 3) Contrôles structurels (fail fast)\n","# ------------------------------------------------------------\n","assert_required_columns(\n","    df_bronze,\n","    [\n","        \"currency\",\n","        \"base_currency\",\n","        \"currency_name\",\n","        \"rate_vs_usd\",\n","        \"date\",\n","        \"source_file\",\n","        \"ingestion_ts\",\n","        \"ingestion_date\"\n","    ]\n",")\n","\n","# ------------------------------------------------------------\n","# 4) Renommage des colonnes métier\n","# ------------------------------------------------------------\n","df = (\n","    df_bronze\n","    .withColumnRenamed(\"date\", \"fx_date\")\n","    .withColumnRenamed(\"rate_vs_usd\", \"rate\")\n",")\n","\n","\n","# ------------------------------------------------------------\n","# 5) Normalisations Silver (via utils)\n","# ------------------------------------------------------------\n","\n","# 5.1 Dates FX (jour + mois)\n","df = add_fx_dates(df, date_col=\"fx_date\")\n","\n","# 5.2 Normalisation des codes devise (ISO)\n","df = normalize_currency_codes(df, cols=[\"currency\", \"base_currency\"])\n","\n","# 5.3 Taux FX (double -> decimal)\n","df = cast_rate(df, col=\"rate\", precision=18, scale=8)\n","\n","# ------------------------------------------------------------\n","# 6) Colonnes techniques & traçabilité\n","# ------------------------------------------------------------\n","df = add_tech_columns(\n","    df,\n","    source_file_col=\"source_file\"\n",")\n","\n","# ------------------------------------------------------------\n","# 7) Hash métier (stabilité & audit)\n","# ------------------------------------------------------------\n","df = add_record_hash(\n","    df,\n","    cols=[\n","        \"currency\",\n","        \"base_currency\",\n","        \"fx_date\",\n","        \"rate\"\n","    ]\n",")\n","\n","\n","# ------------------------------------------------------------\n","# 8) Déduplication Silver\n","# ------------------------------------------------------------\n","\n","# Dedup metrics: measure drops (contract v1.0)\n","_pre_dedup_count = df.count()\n","\n","# Clé naturelle Bronze = (currency, date)\n","# On garde la forme robuste (base_currency, currency, fx_date)\n","df = deduplicate_latest(\n","    df,\n","    key_cols=[\"base_currency\", \"currency\", \"fx_date\"],\n","    order_col=\"ingestion_ts\"\n",")\n","\n","_post_dedup_count = df.count()\n","dedup_dropped = int(_pre_dedup_count - _post_dedup_count)\n","\n","# ------------------------------------------------------------\n","# 9) Projection finale du contrat Silver\n","# ------------------------------------------------------------\n","df = df.select(\n","    # --- Clés & temps ---\n","    \"base_currency\",\n","    \"currency\",\n","    \"currency_name\",\n","    \"fx_date\",\n","    \"fx_month\",\n","\n","    # --- Mesure ---\n","    \"rate\",\n","\n","    # --- Audit ---\n","    \"source_file\",\n","    \"ingestion_date\",\n","    \"ingestion_ts\",\n","    \"record_hash\"\n",")\n","\n","\n","# ------------------------------------------------------------\n","# 9bis) Contrôles gouvernance spécifiques FX (fail fast)\n","# ------------------------------------------------------------\n","fail_fast_checks = []\n","\n","bad_base = df.filter(\n","    F.col(\"base_currency\").isNull() |\n","    (F.col(\"base_currency\") != F.lit(\"EUR\"))\n",")\n","\n","if bad_base.limit(1).count() > 0:\n","    raise ValueError(\n","        \"Invalid base_currency detected: expected EUR (EUR-based FX dataset).\"\n","    )\n","\n","fail_fast_checks.append({\"name\": \"base_currency_is_EUR\", \"passed\": True})\n","\n","# Natural keys not null (fail fast)\n","bad_keys = df.filter(\n","    F.col(\"base_currency\").isNull() |\n","    F.col(\"currency\").isNull() |\n","    F.col(\"fx_date\").isNull()\n",")\n","\n","if bad_keys.limit(1).count() > 0:\n","    raise ValueError(\"Natural key NULL detected in FX rates (base_currency, currency, fx_date).\")\n","\n","fail_fast_checks.append({\"name\": \"natural_keys_not_null\", \"passed\": True})\n","\n","# ------------------------------------------------------------\n","# 10) Écriture Silver gouvernée (partition mensuelle)\n","# ------------------------------------------------------------\n","\n","# --- métriques STANDARD (row_out / partition_count) ---\n","# row_out = nombre de lignes écrites (DF final, après dedupe/projection)\n","row_out = df.count()\n","\n","# partition_count = nb partitions mensuelles réellement présentes (fx_month)\n","partition_count = df.select(\"fx_month\").distinct().count()\n","\n","write_silver_fx_rates(\n","    df,\n","    table_name=\"silver_fx_rates\",\n","    mode=\"overwrite\"\n",")\n","\n","# ------------------------------------------------------------\n","# 11) Fin du notebook\n","# ------------------------------------------------------------\n","_ended = datetime.now(timezone.utc)\n","duration_ms = int((time.time() - _t0) * 1000)\n","\n","# Runtime payload contract v1.0 (Files/governance/runtime/silver/entity_payload.json)\n","payload = {\n","    \"contract_version\": \"1.0\",\n","    \"layer\": \"silver\",\n","    \"run_id\": run_id,\n","    \"entity_code\": entity_code,\n","    \"load_mode\": load_mode,\n","    \"as_of_date\": as_of_date_norm,\n","    \"status\": \"SUCCESS\",\n","    \"metrics\": {\n","        \"row_in\": int(row_in) if row_in is not None else None,\n","        \"row_out\": int(row_out),\n","        \"partition_count\": int(partition_count) if partition_count is not None else 0,\n","        \"dedup_dropped\": int(dedup_dropped)\n","    },\n","    \"table\": {\n","        \"target_table\": \"silver_fx_rates\",\n","        \"partition_cols\": [\"fx_month\"]\n","    },\n","    \"timing\": {\n","        \"started_utc\": _iso_utc(_started),\n","        \"ended_utc\": _iso_utc(_ended),\n","        \"duration_ms\": duration_ms\n","    },\n","    \"quality\": {\n","        \"fail_fast_checks\": fail_fast_checks\n","    },\n","    \"notes\": {\n","        \"message\": None\n","    }\n","}\n","\n","# IMPORTANT: nb_load_silver récupère ce JSON (mssparkutils.notebook.run -> string)\n","mssparkutils.notebook.exit(json.dumps(payload))\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ecf6c31f-e772-44de-a885-5d1bb197ab22"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}