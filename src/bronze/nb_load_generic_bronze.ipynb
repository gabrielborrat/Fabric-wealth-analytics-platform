{"cells":[{"cell_type":"code","source":["# ==========================================\n","# PARAMETER CELL (Fabric Notebook)\n","# ==========================================\n","# Ces variables seront surchargées par le pipeline.\n","# valeurs par défaut pour les tests locaux.\n","\n","LandingPath = \"Files/landing/fx/2025-12-01/fx_sample.csv\"    # chemin complet du fichier en landing\n","ExecDate = \"2025-12-01\"                                      # format 'yyyy-MM-dd'\n","Entity = \"FX\"                                                # 'FX' ou 'CUSTOMER' (ou autre plus tard)\n","\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"tags":["parameters"]},"id":"ad987dd4-6478-4e22-8466-6c36ac0c9934"},{"cell_type":"code","source":["# ==========================================\n","# IMPORTS\n","# ==========================================\n","from pyspark.sql.functions import (\n","    col,\n","    lit,\n","    upper,\n","    trim,\n","    to_date,\n","    current_timestamp\n",")\n","from pyspark.sql import functions as F\n","import re\n","\n","# Normalisation de l'entité en UPPER pour faciliter les comparaisons\n","entity_upper = Entity.upper().strip()\n","\n","# Helper : conversion d'un nom de colonne en snake_case\n","def to_snake(name: str) -> str:\n","    # 1) casser le CamelCase en mots séparés par underscore\n","    s = re.sub(r\"(.)([A-Z][a-z]+)\", r\"\\1_\\2\", name)\n","    s = re.sub(r\"([a-z0-9])([A-Z])\", r\"\\1_\\2\", s)\n","\n","    # 2) passer en lower\n","    s = s.lower()\n","\n","    # 3) remplacements spécifiques\n","    s = s.replace('%', 'pct').replace('&', 'and')\n","\n","    # 4) nettoyer tout ce qui n'est pas alphanumérique en \"_\"\n","    s = re.sub(r\"[^0-9a-z]+\", \"_\", s)\n","    s = re.sub(r\"_+\", \"_\", s).strip(\"_\")\n","\n","    # 5) si ça commence par un chiffre, préfixer\n","    if len(s) > 0 and s[0].isdigit():\n","        s = \"c_\" + s\n","\n","    return s\n","\n","\n","# Helper : normalisation des noms de colonnes pour tous les CSV\n","def normalize_columns(df_raw):\n","    new_cols = []\n","    for c in df_raw.columns:\n","        # Cas particulier fundamentals : première colonne sans nom\n","        if c == \"_c0\":\n","            new_cols.append(\"unnamed_0\")\n","        else:\n","            new_cols.append(to_snake(c))\n","    return df_raw.toDF(*new_cols)\n","\n","# ticker des stocks et etf derives du nom du fichier\n","def extract_ticker(source_file: str):\n","    return F.regexp_extract(F.lit(source_file), r\"([^/]+)\\.us\\.txt$\", 1)\n","\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6507f5eb-7eaf-47eb-869d-55d5133f1eaf"},{"cell_type":"code","source":["# ==========================================\n","# LECTURE DU FICHIER SOURCE (GENERIC)\n","# ==========================================\n","# MCC = JSON multi-lignes de type :\n","# {\n","#   \"5812\": \"Eating Places and Restaurants\",\n","#   \"5921\": \"Package Stores, Beer, Wine, Liquor\",\n","#   ...\n","# }\n","# Tout le reste = CSV classique\n","\n","if entity_upper == \"MCC\":\n","    df_raw = (\n","        spark.read\n","             .format(\"json\")\n","             .option(\"multiLine\", \"true\")   # important pour un gros objet JSON\n","             .load(LandingPath)\n","    )\n","else:\n","    df_raw = (\n","        spark.read\n","             .format(\"csv\")\n","             .option(\"header\", \"true\")\n","             .option(\"inferSchema\", \"true\")\n","             .load(LandingPath)\n","    )\n","\n","display(df_raw.limit(10))\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"95c53c65-d53a-46d9-9c9e-52570b3e0aa0"},{"cell_type":"code","source":["# ==========================================\n","# TRANSFORMATION BRONZE FX\n","# ==========================================\n","def transform_fx(df_raw):\n","    \"\"\"\n","    Transformations Bronze pour les taux FX.\n","    - colonnes d'entrée (après normalisation) :\n","      currency, base_currency, currency_name, exchange_rate, date\n","    \"\"\"\n","    df_norm = normalize_columns(df_raw)\n","\n","    df_fx = (\n","        df_norm\n","            .withColumn(\"currency\", F.upper(F.col(\"currency\")))\n","            .withColumn(\"date\", F.to_date(\"date\"))\n","            .withColumn(\"rate_vs_usd\", F.col(\"exchange_rate\").cast(\"double\"))\n","            .select(\n","                \"currency\",\n","                \"base_currency\",\n","                \"currency_name\",\n","                \"rate_vs_usd\",\n","                \"date\"\n","            )\n","    )\n","\n","    return df_fx\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a56a074f-43d4-4b41-b996-ff90cbe09ad3"},{"cell_type":"code","source":["# ==========================================\n","# TRANSFORMATION BRONZE CUSTOMER (CHURN)\n","# ==========================================\n","def transform_customer(df_raw):\n","    \"\"\"\n","    Transformations Bronze pour le fichier churn.csv.\n","    Convention :\n","    - on passe TOUJOURS par normalize_columns() + to_snake()\n","    - les noms de colonnes sont alignés sur la table bronze_customers_raw\n","    \"\"\"\n","\n","    # 1. Normalisation en snake_case\n","    df_norm = normalize_columns(df_raw)\n","    # Exemples après normalisation :\n","    #   row_number, customer_id, surname, credit_score,\n","    #   geography, gender, age, tenure, balance,\n","    #   num_of_products, has_cr_card, is_active_member,\n","    #   estimated_salary, exited\n","\n","    # 2. Typage cohérent des colonnes numériques\n","    df_typed = (\n","        df_norm\n","            .withColumn(\"row_number\",        col(\"row_number\").cast(\"int\"))\n","            .withColumn(\"customer_id\",       col(\"customer_id\").cast(\"long\"))\n","            .withColumn(\"credit_score\",      col(\"credit_score\").cast(\"int\"))\n","            .withColumn(\"age\",               col(\"age\").cast(\"int\"))\n","            .withColumn(\"tenure\",            col(\"tenure\").cast(\"int\"))\n","            .withColumn(\"balance\",           col(\"balance\").cast(\"double\"))\n","            .withColumn(\"num_of_products\",   col(\"num_of_products\").cast(\"int\"))\n","            .withColumn(\"has_cr_card\",       col(\"has_cr_card\").cast(\"int\"))\n","            .withColumn(\"is_active_member\",  col(\"is_active_member\").cast(\"int\"))\n","            .withColumn(\"estimated_salary\",  col(\"estimated_salary\").cast(\"double\"))\n","            .withColumn(\"exited\",            col(\"exited\").cast(\"int\"))\n","    )\n","\n","    # 3. Normalisation des colonnes texte (UPPER + TRIM)\n","    df_clean = (\n","        df_typed\n","            .withColumn(\"surname\",   upper(trim(col(\"surname\"))))\n","            .withColumn(\"geography\", upper(trim(col(\"geography\"))))\n","            .withColumn(\"gender\",    upper(trim(col(\"gender\"))))\n","    )\n","\n","    # 4. SELECT final aligné sur la table bronze_customers_raw\n","    df_final = df_clean.select(\n","        \"row_number\",\n","        \"customer_id\",\n","        \"surname\",\n","        \"credit_score\",\n","        \"geography\",\n","        \"gender\",\n","        \"age\",\n","        \"tenure\",\n","        \"balance\",\n","        \"num_of_products\",\n","        \"has_cr_card\",\n","        \"is_active_member\",\n","        \"estimated_salary\",\n","        \"exited\"\n","    )\n","\n","    return df_final\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4d5fcc96-5941-43aa-a3c0-397d3aa8f30d"},{"cell_type":"code","source":["def load_securities(df_raw):\n","    \"\"\"\n","    Transformations Bronze pour securities.csv\n","    \"\"\"\n","    # Étape 1 : normalisation des noms de colonnes\n","    df_norm = normalize_columns(df_raw)\n","    # => ticker_symbol, security, sec_filings, gics_sector, gics_sub_industry,\n","    #    address_of_headquarters, date_first_added, cik\n","\n","    # Étape 2 : typage + normalisation\n","    df_typed = (\n","        df_norm\n","            .withColumn(\"date_first_added\", F.to_date(\"date_first_added\"))\n","            .withColumn(\"ticker_symbol\",    upper(col(\"ticker_symbol\")))\n","            .withColumn(\"cik\",              col(\"cik\").cast(\"string\"))\n","    )\n","\n","    # Étape 3 : SELECT final aligné sur bronze_securities_raw\n","    df_final = df_typed.select(\n","        \"ticker_symbol\",\n","        \"security\",\n","        \"sec_filings\",\n","        \"gics_sector\",\n","        \"gics_sub_industry\",\n","        \"address_of_headquarters\",\n","        \"date_first_added\",\n","        \"cik\"\n","    )\n","\n","    return df_final\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"55b1b0b2-59dd-4f60-ad9a-6c16c8f74b88"},{"cell_type":"code","source":["def load_fundamentals(df_raw):\n","    \"\"\"\n","    Transformations Bronze pour fundamentals.csv\n","    Étapes :\n","    1. Normalisation des noms de colonnes (normalize_columns + to_snake)\n","    2. Typage spécifique :\n","       - unnamed_0 -> BIGINT (long)\n","       - period_ending -> DATE\n","    \"\"\"\n","\n","    # Étape 1 : normalisation des noms de colonnes\n","    df_norm = normalize_columns(df_raw)\n","    # => unnamed_0, ticker_symbol, period_ending, ...\n","\n","    # Étape 2 : typage ciblé\n","    df_typed = df_norm\n","\n","    if \"unnamed_0\" in df_typed.columns:\n","        df_typed = df_typed.withColumn(\"unnamed_0\", col(\"unnamed_0\").cast(\"long\"))\n","\n","    if \"period_ending\" in df_typed.columns:\n","        df_typed = df_typed.withColumn(\"period_ending\", F.to_date(\"period_ending\"))\n","\n","    # Étape 3 : SELECT final aligné sur bronze_fundamentals_raw\n","    df_final = df_typed.select(\n","        \"unnamed_0\",\n","        \"ticker_symbol\",\n","        \"period_ending\",\n","        \"accounts_payable\",\n","        \"accounts_receivable\",\n","        \"add_l_income_expense_items\",\n","        \"after_tax_roe\",\n","        \"capital_expenditures\",\n","        \"capital_surplus\",\n","        \"cash_ratio\",\n","        \"cash_and_cash_equivalents\",\n","        \"changes_in_inventories\",\n","        \"common_stocks\",\n","        \"cost_of_revenue\",\n","        \"current_ratio\",\n","        \"deferred_asset_charges\",\n","        \"deferred_liability_charges\",\n","        \"depreciation\",\n","        \"earnings_before_interest_and_tax\",\n","        \"earnings_before_tax\",\n","        \"effect_of_exchange_rate\",\n","        \"equity_earnings_loss_unconsolidated_subsidiary\",\n","        \"fixed_assets\",\n","        \"goodwill\",\n","        \"gross_margin\",\n","        \"gross_profit\",\n","        \"income_tax\",\n","        \"intangible_assets\",\n","        \"interest_expense\",\n","        \"inventory\",\n","        \"investments\",\n","        \"liabilities\",\n","        \"long_term_debt\",\n","        \"long_term_investments\",\n","        \"minority_interest\",\n","        \"misc_stocks\",\n","        \"net_borrowings\",\n","        \"net_cash_flow\",\n","        \"net_cash_flow_operating\",\n","        \"net_cash_flows_financing\",\n","        \"net_cash_flows_investing\",\n","        \"net_income\",\n","        \"net_income_adjustments\",\n","        \"net_income_applicable_to_common_shareholders\",\n","        \"net_income_cont_operations\",\n","        \"net_receivables\",\n","        \"non_recurring_items\",\n","        \"operating_income\",\n","        \"operating_margin\",\n","        \"other_assets\",\n","        \"other_current_assets\",\n","        \"other_current_liabilities\",\n","        \"other_equity\",\n","        \"other_financing_activities\",\n","        \"other_investing_activities\",\n","        \"other_liabilities\",\n","        \"other_operating_activities\",\n","        \"other_operating_items\",\n","        \"pre_tax_margin\",\n","        \"pre_tax_roe\",\n","        \"profit_margin\",\n","        \"quick_ratio\",\n","        \"research_and_development\",\n","        \"retained_earnings\",\n","        \"sale_and_purchase_of_stock\",\n","        \"sales_general_and_admin\",\n","        \"short_term_debt_current_portion_of_long_term_debt\",\n","        \"short_term_investments\",\n","        \"total_assets\",\n","        \"total_current_assets\",\n","        \"total_current_liabilities\",\n","        \"total_equity\",\n","        \"total_liabilities\",\n","        \"total_liabilities_and_equity\",\n","        \"total_revenue\",\n","        \"treasury_stock\",\n","        \"for_year\",\n","        \"earnings_per_share\",\n","        \"estimated_shares_outstanding\"\n","    )\n","\n","    return df_final\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e2097b9d-0e4b-4145-8538-b7d462dea797"},{"cell_type":"code","source":["def load_prices(df_raw):\n","    \"\"\"\n","    Transformations Bronze pour prices.csv\n","    \"\"\"\n","    df_norm = normalize_columns(df_raw)\n","\n","    df_typed = (\n","        df_norm\n","            .withColumn(\"date\",   F.to_timestamp(\"date\"))\n","            .withColumn(\"open\",   col(\"open\").cast(\"double\"))\n","            .withColumn(\"close\",  col(\"close\").cast(\"double\"))\n","            .withColumn(\"low\",    col(\"low\").cast(\"double\"))\n","            .withColumn(\"high\",   col(\"high\").cast(\"double\"))\n","            .withColumn(\"volume\", col(\"volume\").cast(\"double\"))\n","    )\n","\n","    df_final = df_typed.select(\n","        \"date\",\n","        \"symbol\",\n","        \"open\",\n","        \"close\",\n","        \"low\",\n","        \"high\",\n","        \"volume\"\n","    )\n","\n","    return df_final\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2505d34f-b0c9-4042-8591-36ea17868cfe"},{"cell_type":"code","source":["def load_prices_split_adjusted(df_raw):\n","    \"\"\"\n","    Transformations Bronze pour prices-split-adjusted.csv\n","    \"\"\"\n","    df_norm = normalize_columns(df_raw)\n","\n","    df_typed = (\n","        df_norm\n","            .withColumn(\"date\",   F.to_timestamp(\"date\"))\n","            .withColumn(\"open\",   col(\"open\").cast(\"double\"))\n","            .withColumn(\"close\",  col(\"close\").cast(\"double\"))\n","            .withColumn(\"low\",    col(\"low\").cast(\"double\"))\n","            .withColumn(\"high\",   col(\"high\").cast(\"double\"))\n","            .withColumn(\"volume\", col(\"volume\").cast(\"double\"))\n","    )\n","\n","    df_final = df_typed.select(\n","        \"date\",\n","        \"symbol\",\n","        \"open\",\n","        \"close\",\n","        \"low\",\n","        \"high\",\n","        \"volume\"\n","    )\n","\n","    return df_final\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ac6e4f73-6172-46a5-9f3f-ba5a16a25092"},{"cell_type":"code","source":["# ==========================================\n","# TRANSFORMATION BRONZE ETF\n","# ==========================================\n","def load_etf(df_raw):\n","    \"\"\"\n","    Transformations Bronze pour les fichiers ETF au format OHLCV.\n","    Colonnes attendues après normalize_columns():\n","      ticker, date, open, high, low, close, volume, open_int\n","    La colonne ticker est lue directement depuis le fichier.\n","    \"\"\"\n","    df_norm = normalize_columns(df_raw)\n","\n","    df_typed = (\n","        df_norm\n","            # ticker en snake_case déjà présent après normalize_columns()\n","            .withColumn(\"ticker\", upper(trim(col(\"ticker\"))))\n","            .withColumn(\"date\",   F.to_date(\"date\", \"yyyy-MM-dd\"))\n","            .withColumn(\"open\",   col(\"open\").cast(\"double\"))\n","            .withColumn(\"high\",   col(\"high\").cast(\"double\"))\n","            .withColumn(\"low\",    col(\"low\").cast(\"double\"))\n","            .withColumn(\"close\",  col(\"close\").cast(\"double\"))\n","            .withColumn(\"volume\",   col(\"volume\").cast(\"bigint\"))\n","            .withColumn(\"open_int\", col(\"open_int\").cast(\"bigint\"))\n","    )\n","\n","    df_final = df_typed.select(\n","        \"ticker\",\n","        \"date\",\n","        \"open\",\n","        \"high\",\n","        \"low\",\n","        \"close\",\n","        \"volume\",\n","        \"open_int\"\n","    )\n","\n","    return df_final\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"70ea3c73-ad6c-4a94-aaf4-2a8574beb6d7"},{"cell_type":"code","source":["# ==========================================\n","# TRANSFORMATION BRONZE STOCK\n","# ==========================================\n","def load_stock(df_raw):\n","    \"\"\"\n","    Transformations Bronze pour les fichiers STOCK au format OHLCV.\n","    Colonnes attendues après normalize_columns():\n","      ticker, date, open, high, low, close, volume, open_int\n","    La colonne ticker est lue directement depuis le fichier.\n","    \"\"\"\n","    df_norm = normalize_columns(df_raw)\n","\n","    df_typed = (\n","        df_norm\n","            .withColumn(\"ticker\", upper(trim(col(\"ticker\"))))\n","            .withColumn(\"date\",   F.to_date(\"date\", \"yyyy-MM-dd\"))\n","            .withColumn(\"open\",   col(\"open\").cast(\"double\"))\n","            .withColumn(\"high\",   col(\"high\").cast(\"double\"))\n","            .withColumn(\"low\",    col(\"low\").cast(\"double\"))\n","            .withColumn(\"close\",  col(\"close\").cast(\"double\"))\n","            .withColumn(\"volume\",   col(\"volume\").cast(\"bigint\"))\n","            .withColumn(\"open_int\", col(\"open_int\").cast(\"bigint\"))\n","    )\n","\n","    df_final = df_typed.select(\n","        \"ticker\",\n","        \"date\",\n","        \"open\",\n","        \"high\",\n","        \"low\",\n","        \"close\",\n","        \"volume\",\n","        \"open_int\"\n","    )\n","\n","    return df_final\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e84e4b03-6436-461e-9085-2255e63e1994"},{"cell_type":"code","source":["# ==========================================\n","# TRANSFORMATION BRONZE CARDS\n","# ==========================================\n","def load_cards(df_raw):\n","    \"\"\"\n","    Transformations Bronze pour cards_data.csv.\n","    Colonnes attendues après normalize_columns():\n","      id, client_id, card_brand, card_type, card_number,\n","      expires, cvv, has_chip, num_cards_issued,\n","      credit_limit, acct_open_date, year_pin_last_changed,\n","      card_on_dark_web\n","    \"\"\"\n","    df_norm = normalize_columns(df_raw)\n","\n","    df_typed = (\n","        df_norm\n","            # Identifiants et numériques\n","            .withColumn(\"id\",                col(\"id\").cast(\"bigint\"))\n","            .withColumn(\"client_id\",         col(\"client_id\").cast(\"bigint\"))\n","            .withColumn(\"num_cards_issued\",  col(\"num_cards_issued\").cast(\"int\"))\n","            .withColumn(\"year_pin_last_changed\", col(\"year_pin_last_changed\").cast(\"int\"))\n","            # Texte / catégories normalisées\n","            .withColumn(\"card_brand\",  upper(trim(col(\"card_brand\"))))\n","            .withColumn(\"card_type\",   upper(trim(col(\"card_type\"))))\n","            .withColumn(\"has_chip\",    upper(trim(col(\"has_chip\"))))\n","            .withColumn(\"card_on_dark_web\", upper(trim(col(\"card_on_dark_web\"))))\n","            # Numéros sensibles conservés en string\n","            .withColumn(\"card_number\", col(\"card_number\").cast(\"string\"))\n","            .withColumn(\"cvv\",         col(\"cvv\").cast(\"string\"))\n","            # Limite de crédit : suppression de \"$\" puis cast en double\n","            .withColumn(\n","                \"credit_limit\",\n","                F.regexp_replace(\"credit_limit\", r\"[^0-9.]\", \"\").cast(\"double\")\n","            )\n","            # Dates : on reste en string en Bronze (MM/YYYY, MM/YYYY)\n","            .withColumn(\"expires\",        col(\"expires\").cast(\"string\"))\n","            .withColumn(\"acct_open_date\", col(\"acct_open_date\").cast(\"string\"))\n","    )\n","\n","    df_final = df_typed.select(\n","        \"id\",\n","        \"client_id\",\n","        \"card_brand\",\n","        \"card_type\",\n","        \"card_number\",\n","        \"expires\",\n","        \"cvv\",\n","        \"has_chip\",\n","        \"num_cards_issued\",\n","        \"credit_limit\",\n","        \"acct_open_date\",\n","        \"year_pin_last_changed\",\n","        \"card_on_dark_web\"\n","    )\n","\n","    return df_final"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5ee505d4-6642-4df7-9e18-321ebde3ac39"},{"cell_type":"code","source":["# ==========================================\n","# TRANSFORMATION BRONZE USERS\n","# ==========================================\n","def load_users(df_raw):\n","    \"\"\"\n","    Transformations Bronze pour users_data.csv.\n","    Colonnes attendues après normalize_columns():\n","      id, current_age, retirement_age, birth_year, birth_month,\n","      gender, address, latitude, longitude,\n","      per_capita_income, yearly_income, total_debt,\n","      credit_score, num_credit_cards\n","    \"\"\"\n","    df_norm = normalize_columns(df_raw)\n","\n","    df_typed = (\n","        df_norm\n","            # Identifiants & âges\n","            .withColumn(\"id\",             col(\"id\").cast(\"bigint\"))\n","            .withColumn(\"current_age\",    col(\"current_age\").cast(\"int\"))\n","            .withColumn(\"retirement_age\", col(\"retirement_age\").cast(\"int\"))\n","            .withColumn(\"birth_year\",     col(\"birth_year\").cast(\"int\"))\n","            .withColumn(\"birth_month\",    col(\"birth_month\").cast(\"int\"))\n","            # Coordonnées\n","            .withColumn(\"latitude\",  col(\"latitude\").cast(\"double\"))\n","            .withColumn(\"longitude\", col(\"longitude\").cast(\"double\"))\n","            # Texte\n","            .withColumn(\"gender\",  upper(trim(col(\"gender\"))))\n","            .withColumn(\"address\", trim(col(\"address\")))\n","            # Montants monétaires : suppression de \"$\" puis cast\n","            .withColumn(\n","                \"per_capita_income\",\n","                F.regexp_replace(\"per_capita_income\", r\"[^0-9.]\", \"\").cast(\"double\")\n","            )\n","            .withColumn(\n","                \"yearly_income\",\n","                F.regexp_replace(\"yearly_income\", r\"[^0-9.]\", \"\").cast(\"double\")\n","            )\n","            .withColumn(\n","                \"total_debt\",\n","                F.regexp_replace(\"total_debt\", r\"[^0-9.]\", \"\").cast(\"double\")\n","            )\n","            # Score & nombre de cartes\n","            .withColumn(\"credit_score\",     col(\"credit_score\").cast(\"int\"))\n","            .withColumn(\"num_credit_cards\", col(\"num_credit_cards\").cast(\"int\"))\n","    )\n","\n","    df_final = df_typed.select(\n","        \"id\",\n","        \"current_age\",\n","        \"retirement_age\",\n","        \"birth_year\",\n","        \"birth_month\",\n","        \"gender\",\n","        \"address\",\n","        \"latitude\",\n","        \"longitude\",\n","        \"per_capita_income\",\n","        \"yearly_income\",\n","        \"total_debt\",\n","        \"credit_score\",\n","        \"num_credit_cards\"\n","    )\n","\n","    return df_final"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"11c7fdad-4c75-43de-a157-2dd7d2ad93ff"},{"cell_type":"code","source":["# ==========================================\n","# TRANSFORMATION BRONZE TRANSACTIONS\n","# ==========================================\n","def load_transactions(df_raw):\n","    \"\"\"\n","    Transformations Bronze pour transactions_data.csv.\n","    Colonnes attendues (header CSV) :\n","      id, date, client_id, card_id, amount, use_chip,\n","      merchant_id, merchant_city, merchant_state, zip, mcc, errors\n","    \"\"\"\n","\n","    # 1. Normalisation éventuelle (garantie snake_case)\n","    df_norm = normalize_columns(df_raw)\n","\n","    # 2. Typage & nettoyage\n","    df_typed = (\n","        df_norm\n","            # Identifiants\n","            .withColumn(\"id\",          col(\"id\").cast(\"bigint\"))\n","            .withColumn(\"client_id\",   col(\"client_id\").cast(\"bigint\"))\n","            .withColumn(\"card_id\",     col(\"card_id\").cast(\"bigint\"))\n","            .withColumn(\"merchant_id\", col(\"merchant_id\").cast(\"bigint\"))\n","\n","            # Date/heure de la transaction\n","            .withColumn(\"date\", F.to_timestamp(\"date\"))\n","\n","            # Montant : suppression de \"$\", \",\" etc. avant cast en DOUBLE\n","            .withColumn(\n","                \"amount\",\n","                F.regexp_replace(\"amount\", r\"[^0-9\\.\\-]\", \"\").cast(\"double\")\n","            )\n","\n","            # Champs texte : normalisation\n","            .withColumn(\"use_chip\",       upper(trim(col(\"use_chip\"))))\n","            .withColumn(\"merchant_city\",  upper(trim(col(\"merchant_city\"))))\n","            .withColumn(\"merchant_state\", upper(trim(col(\"merchant_state\"))))\n","\n","            # ZIP + codes\n","            .withColumn(\"zip\",    trim(col(\"zip\").cast(\"string\")))\n","            .withColumn(\"mcc\",    col(\"mcc\").cast(\"int\"))\n","            .withColumn(\"errors\", col(\"errors\").cast(\"int\"))\n","    )\n","\n","    # 3. SELECT final aligné sur la table bronze_transactions_raw\n","    df_final = df_typed.select(\n","        \"id\",\n","        \"date\",\n","        \"client_id\",\n","        \"card_id\",\n","        \"amount\",\n","        \"use_chip\",\n","        \"merchant_id\",\n","        \"merchant_city\",\n","        \"merchant_state\",\n","        \"zip\",\n","        \"mcc\",\n","        \"errors\"\n","    )\n","\n","    return df_final\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"62bc9f5a-889e-4d5a-a3dd-6a7e49b25cb4"},{"cell_type":"code","source":["# ==========================================\n","# TRANSFORMATION BRONZE MCC\n","# ==========================================\n","def load_mcc(df_raw):\n","    \"\"\"\n","    Transformations Bronze pour le fichier MCC JSON.\n","    JSON attendu :\n","      {\n","        \"5812\": \"Eating Places and Restaurants\",\n","        \"5921\": \"Package Stores, Beer, Wine, Liquor\",\n","        ...\n","      }\n","\n","    df_raw : une seule ligne, avec une colonne par code MCC (\"5812\", \"5921\", ...)\n","    On convertit ça en lignes : (mcc, mcc_description).\n","    \"\"\"\n","\n","    cols = df_raw.columns\n","\n","    df_map = df_raw.select(\n","        F.explode(\n","            F.map_from_arrays(\n","                F.array(*[F.lit(c) for c in cols]),     # clés = codes MCC (string)\n","                F.array(*[F.col(c) for c in cols])      # valeurs = descriptions\n","            )\n","        ).alias(\"mcc\", \"mcc_description\")\n","    )\n","\n","    df_typed = (\n","        df_map\n","            .withColumn(\"mcc\",           F.col(\"mcc\").cast(\"int\"))\n","            .withColumn(\"mcc_description\", F.trim(F.col(\"mcc_description\")))\n","    )\n","\n","    # SELECT final aligné sur bronze_mcc_raw\n","    df_final = df_typed.select(\n","        \"mcc\",\n","        \"mcc_description\"\n","    )\n","\n","    return df_final\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"aaf5f2ec-fc26-44b1-8924-8eea9e827f4a"},{"cell_type":"code","source":["# ==========================================\n","# DISPATCHER SELON ENTITY + COLONNES TECHNIQUES\n","# ==========================================\n","\n","if entity_upper == \"FX\":\n","    df_core = transform_fx(df_raw)\n","    target_table = \"bronze_fx_raw\"\n","\n","elif entity_upper == \"CUSTOMER\":\n","    df_core = transform_customer(df_raw)\n","    target_table = \"bronze_customers_raw\"\n","\n","elif entity_upper == \"SECURITIES\":\n","    df_core = load_securities(df_raw)\n","    target_table = \"bronze_securities_raw\"\n","\n","elif entity_upper == \"FUNDAMENTALS\":\n","    df_core = load_fundamentals(df_raw)\n","    target_table = \"bronze_fundamentals_raw\"\n","\n","elif entity_upper == \"PRICES\":\n","    df_core = load_prices(df_raw)\n","    target_table = \"bronze_prices_raw\"\n","\n","elif entity_upper == \"PRICES_SPLIT_ADJUSTED\":\n","    df_core = load_prices_split_adjusted(df_raw)\n","    target_table = \"bronze_prices_split_adjusted_raw\"\n","\n","elif entity_upper == \"ETF\":\n","    df_core = load_etf(df_raw)\n","    target_table = \"bronze_etf_raw\"\n","\n","elif entity_upper == \"STOCK\":\n","    df_core = load_stock(df_raw)\n","    target_table = \"bronze_stock_raw\"\n","\n","\n","elif entity_upper == \"CARD\":\n","    df_core = load_cards(df_raw)\n","    target_table = \"bronze_card_raw\"\n","\n","elif entity_upper == \"USER\":\n","    df_core = load_users(df_raw)\n","    target_table = \"bronze_user_raw\"\n","\n","elif entity_upper == \"TRANSACTION\":\n","    df_core = load_transactions(df_raw)\n","    target_table = \"bronze_transactions_raw\"\n","\n","elif entity_upper == \"MCC\":\n","    df_core = load_mcc(df_raw)\n","    target_table = \"bronze_mcc_raw\"\n","\n","else:\n","    # Fallback générique : on ne transforme presque pas, mais on loggue quand même\n","    # Utile si ajout d'autres entités plus tard.\n","    df_core = df_raw\n","    target_table = f\"bronze_{entity_upper.lower()}_raw\"\n","\n","\n","# Ajout des colonnes techniques communes\n","df_bronze = (\n","    df_core\n","        # Source file : ici on garde le chemin complet tel qu'il arrive du pipeline\n","        .withColumn(\"source_file\",   lit(LandingPath))\n","        # Ingestion_date : date logique du run (ExecDate)\n","        .withColumn(\"ingestion_date\", to_date(lit(ExecDate), \"yyyy-MM-dd\"))\n","        # Ingestion_ts : timestamp technique\n","        .withColumn(\"ingestion_ts\",  current_timestamp())\n","        # Entity : pour retrouver facilement l'origine\n","        .withColumn(\"entity\",        lit(entity_upper))\n",")\n","\n","display(df_bronze.limit(10))\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"16546cec-9d69-42e7-b4cb-50ff8d45d788"},{"cell_type":"code","source":["# ==========================================\n","# ÉCRITURE DANS LA TABLE BRONZE\n","# ==========================================\n","# IMPORTANT :\n","# - Le notebook doit être lié au Lakehouse `lh_wm_core`.\n","# - Les tables seront créées automatiquement en Delta dans ce Lakehouse.\n","\n","(\n","    df_bronze\n","        .write\n","        .mode(\"append\")\n","        .format(\"delta\")\n","        .saveAsTable(target_table)\n",")\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"742b64ca-7360-48bd-bd7a-1f6493467fd0"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"86de7d18-06e4-4a37-ac0b-fbd45cf4157a"}],"default_lakehouse":"86de7d18-06e4-4a37-ac0b-fbd45cf4157a","default_lakehouse_name":"lh_wm_core","default_lakehouse_workspace_id":"300f0249-d03f-436c-97fc-5b5940cc3aa3"}}},"nbformat":4,"nbformat_minor":5}