{"cells":[{"cell_type":"code","source":["#!/usr/bin/env python\n","# coding: utf-8\n","\n","# ============================================================\n","# nb_gold_fact_transactions_v1_0_final — Gold Fact: Transactions\n","#\n","# Contract-first + data-driven execution (banking-ready)\n","# - No runtime args / widgets\n","# - Reads execution context from gold_log_steps (latest RUNNING for this notebook)\n","# - Option A: keep error_code; derive is_chip_used; keep is_success\n","# - Dedup keep_latest by ingestion_ts\n","# - Strict dimensional conformance:\n","#     ORPHAN_DIM_USER, ORPHAN_DIM_CARD, ORPHAN_DIM_MCC, ORPHAN_DIM_DATE\n","#   Non-conforming rows excluded from Gold and logged as anomalies (append-only)\n","# - Idempotent rebuild (TRUNCATE + APPEND) partitioned by txn_month\n","# - Returns deterministic metrics to dispatcher via exit_payload\n","# ============================================================\n","\n","# The command is not a standard IPython magic command. It is designed for use within Fabric notebooks only."],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"440a5340-7801-4d13-8b56-f54ad9b3f4bc"},{"cell_type":"code","source":["%run ./nb_gold_utils"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4a33138a-4f00-404d-8533-235873d462df"},{"cell_type":"code","source":["from pyspark.sql import functions as F\n","from pyspark.sql.window import Window\n","import json\n","\n","# -----------------------------\n","# 0) Data-driven execution context\n","# -----------------------------\n","LOG_STEPS_TABLE = \"gold_log_steps\"\n","THIS_NOTEBOOK   = \"nb_gold_fact_transactions\"\n","\n","def _json_load_safe(s: str) -> dict:\n","    try:\n","        return json.loads(s) if s else {}\n","    except Exception:\n","        return {}\n","\n","def read_ctx_from_steps() -> dict:\n","    df = (\n","        spark.table(LOG_STEPS_TABLE)\n","        .filter((F.col(\"notebook_name\") == THIS_NOTEBOOK) & (F.col(\"status\") == \"RUNNING\"))\n","        .orderBy(F.col(\"start_ts\").desc())\n","        .limit(1)\n","    )\n","    rows = df.collect()\n","    if not rows:\n","        raise ValueError(\n","            f\"[{THIS_NOTEBOOK}] No RUNNING step found in {LOG_STEPS_TABLE}. \"\n","            \"Dispatcher must write RUNNING ctx before execution.\"\n","        )\n","\n","    payload = _json_load_safe(rows[0][\"payload_json\"])\n","    ctx = payload.get(\"ctx\", {})\n","    if not isinstance(ctx, dict) or not ctx:\n","        raise ValueError(f\"[{THIS_NOTEBOOK}] RUNNING step payload_json has no ctx.\")\n","\n","    # Hard validations (banking-grade)\n","    if str(ctx.get(\"notebook_name\", \"\")).strip() != THIS_NOTEBOOK:\n","        raise ValueError(f\"[{THIS_NOTEBOOK}] ctx.notebook_name mismatch: {ctx.get('notebook_name')}\")\n","    if str(ctx.get(\"gold_run_id\", \"\")).strip() == \"\":\n","        raise ValueError(f\"[{THIS_NOTEBOOK}] ctx.gold_run_id missing\")\n","    if str(ctx.get(\"step_exec_id\", \"\")).strip() == \"\":\n","        raise ValueError(f\"[{THIS_NOTEBOOK}] ctx.step_exec_id missing\")\n","    if str(ctx.get(\"entity_code\", \"\")).strip() == \"\":\n","        raise ValueError(f\"[{THIS_NOTEBOOK}] ctx.entity_code missing\")\n","\n","    return ctx\n","\n","ctx = read_ctx_from_steps()\n","\n","gold_run_id  = normalize_run_id(ctx[\"gold_run_id\"])\n","step_exec_id = ctx[\"step_exec_id\"]\n","entity_code  = ctx[\"entity_code\"]\n","load_mode    = ctx.get(\"load_mode\", \"\")\n","as_of_date   = ctx.get(\"as_of_date\", \"\")\n","\n","print(f\"gold_run_id   = {gold_run_id}\")\n","print(f\"step_exec_id  = {step_exec_id}\")\n","print(f\"entity_code   = {entity_code}\")\n","print(f\"load_mode     = {load_mode}\")\n","print(f\"as_of_date    = {as_of_date}\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"tags":["parameters"]},"id":"f4754859-4415-4587-9f54-adeedf192fd0"},{"cell_type":"code","source":["# -----------------------------\n","# 1) Tables / constants\n","# -----------------------------\n","SILVER_TABLE = \"silver_transactions\"\n","GOLD_TABLE   = \"gold_fact_transactions\"\n","\n","DIM_USER = \"gold_dim_user\"\n","DIM_CARD = \"gold_dim_card\"\n","DIM_MCC  = \"gold_dim_mcc\"\n","DIM_DATE = \"gold_dim_date\"\n","\n","ENTITY       = GOLD_TABLE\n","SOURCE_TABLE = SILVER_TABLE"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3065da2e-9f66-4cb4-b7e0-7cf9cdb8689f"},{"cell_type":"code","source":["# -----------------------------\n","# 2) Read Silver (input sanity — minimal required)\n","# -----------------------------\n","df_silver = spark.table(SILVER_TABLE)\n","\n","INPUT_REQUIRED = [\n","    \"transaction_id\",\"txn_ts\",\"txn_date\",\"txn_month\",\"client_id\",\"card_id\",\n","    \"merchant_id\",\"mcc_code\",\"amount\",\"use_chip\",\"merchant_city\",\"merchant_state\",\n","    \"zip\",\"error_code\",\"is_success\",\n","    \"source_file\",\"ingestion_date\",\"ingestion_ts\",\"record_hash\"\n","]\n","assert_required_columns(df_silver, INPUT_REQUIRED, ctx=f\"{SILVER_TABLE} (input)\")\n","\n","df_work = df_silver.select(*[F.col(c) for c in INPUT_REQUIRED])\n","row_in = df_work.count()"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f51195c7-e434-42ec-89a6-7265f78df8ba"},{"cell_type":"code","source":["# -----------------------------\n","# 3) Derivations (Gold business-friendly) — Option A\n","# -----------------------------\n","df_work = df_work.withColumn(\n","    \"use_chip\",\n","    F.when(F.col(\"use_chip\").isNull(), F.lit(None).cast(\"string\"))\n","     .otherwise(F.trim(F.col(\"use_chip\").cast(\"string\")))\n",")\n","\n","df_work = df_work.withColumn(\n","    \"is_chip_used\",\n","    F.when(F.col(\"use_chip\").isNull(), F.lit(None).cast(\"boolean\"))\n","     .when(F.upper(F.col(\"use_chip\")).contains(\"CHIP\"), F.lit(True))\n","     .otherwise(F.lit(False))\n",")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d4d34344-228e-4ab6-a512-d20cedbc9d13"},{"cell_type":"code","source":["# -----------------------------\n","# 4) Dedup keep_latest (transaction_id by ingestion_ts)\n","# -----------------------------\n","w = Window.partitionBy(\"transaction_id\").orderBy(F.col(\"ingestion_ts\").desc())\n","\n","df_dedup = (\n","    df_work\n","    .withColumn(\"_rn\", F.row_number().over(w))\n","    .filter(F.col(\"_rn\") == 1)\n","    .drop(\"_rn\")\n",")\n","\n","row_after_dedup = df_dedup.count()\n","dedup_dropped = row_in - row_after_dedup\n","\n","# Banking-grade uniqueness post-dedup\n","assert_unique_key(df_dedup, [\"transaction_id\"], ctx=f\"{ENTITY} (post-dedup)\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"aa7055c4-1778-46bc-9fef-871cd1be99f0"},{"cell_type":"code","source":["# -----------------------------\n","# 5) Load dimensions (keys only)\n","# -----------------------------\n","df_users = spark.table(DIM_USER).select(F.col(\"client_id\").cast(\"BIGINT\").alias(\"client_id\")).dropDuplicates()\n","df_cards = spark.table(DIM_CARD).select(F.col(\"card_id\").cast(\"BIGINT\").alias(\"card_id\")).dropDuplicates()\n","df_mcc   = spark.table(DIM_MCC).select(F.col(\"mcc_code\").cast(\"STRING\").alias(\"mcc_code\")).dropDuplicates()\n","\n","# gold_dim_date business key: date_value\n","df_dates = spark.table(DIM_DATE).select(F.col(\"date_value\").cast(\"DATE\").alias(\"txn_date\")).dropDuplicates()"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"362628e9-1e05-4b20-874e-eee70260120d"},{"cell_type":"code","source":["# -----------------------------\n","# 6) Conformance + anomalies (append-only, audit-ready)\n","#    Strict rule: exclude non-conforming rows from Gold fact.\n","# -----------------------------\n","df_ok_1, anom_user = split_orphans_left_anti(\n","    fact_df=df_dedup,\n","    dim_df=df_users,\n","    fact_key=\"client_id\",\n","    dim_key=\"client_id\",\n","    rule_id=\"GOLD.TXN.CONF.001\",\n","    anom_type=\"ORPHAN_DIM_USER\",\n","    entity=ENTITY,\n","    gold_run_id=gold_run_id,\n","    source_table=SOURCE_TABLE,\n","    severity=\"HIGH\",\n","    natural_key_cols_for_event=[\"transaction_id\",\"client_id\"]\n",")\n","\n","df_ok_2, anom_card = split_orphans_left_anti(\n","    fact_df=df_ok_1,\n","    dim_df=df_cards,\n","    fact_key=\"card_id\",\n","    dim_key=\"card_id\",\n","    rule_id=\"GOLD.TXN.CONF.002\",\n","    anom_type=\"ORPHAN_DIM_CARD\",\n","    entity=ENTITY,\n","    gold_run_id=gold_run_id,\n","    source_table=SOURCE_TABLE,\n","    severity=\"HIGH\",\n","    natural_key_cols_for_event=[\"transaction_id\",\"card_id\"]\n",")\n","\n","df_ok_3, anom_mcc = split_orphans_left_anti(\n","    fact_df=df_ok_2,\n","    dim_df=df_mcc,\n","    fact_key=\"mcc_code\",\n","    dim_key=\"mcc_code\",\n","    rule_id=\"GOLD.TXN.CONF.003\",\n","    anom_type=\"ORPHAN_DIM_MCC\",\n","    entity=ENTITY,\n","    gold_run_id=gold_run_id,\n","    source_table=SOURCE_TABLE,\n","    severity=\"MEDIUM\",\n","    natural_key_cols_for_event=[\"transaction_id\",\"mcc_code\"]\n",")\n","\n","df_conformed, anom_date = split_orphans_left_anti(\n","    fact_df=df_ok_3,\n","    dim_df=df_dates,\n","    fact_key=\"txn_date\",\n","    dim_key=\"txn_date\",\n","    rule_id=\"GOLD.TXN.CONF.004\",\n","    anom_type=\"ORPHAN_DIM_DATE\",\n","    entity=ENTITY,\n","    gold_run_id=gold_run_id,\n","    source_table=SOURCE_TABLE,\n","    severity=\"HIGH\",\n","    natural_key_cols_for_event=[\"transaction_id\",\"txn_date\"]\n",")\n","\n","anom_all = anom_user.unionByName(anom_card).unionByName(anom_mcc).unionByName(anom_date)\n","\n","# Single action on anomalies\n","anom_count = anom_all.count()\n","if anom_count > 0:\n","    write_anomaly_events(anom_all, table_name=\"gold_anomaly_event\")\n","    write_anomaly_kpis(\n","        anom_all,\n","        gold_run_id=gold_run_id,\n","        entity=ENTITY,\n","        table_name=\"gold_anomaly_kpi\",\n","        sample_limit=10\n","    )\n","\n","row_conformed = df_conformed.count()\n","row_rejected = row_after_dedup - row_conformed\n","\n","print(f\"row_in={row_in}, row_after_dedup={row_after_dedup}, row_conformed={row_conformed}, row_rejected={row_rejected}, anom_count={anom_count}\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"15176698-4090-4814-b801-6045b24209f0"},{"cell_type":"code","source":["# -----------------------------\n","# 7) Add Gold technical columns + minor standardizations\n","# -----------------------------\n","df_conformed = df_conformed.withColumn(\"error_code\", F.coalesce(F.col(\"error_code\"), F.lit(0)).cast(\"int\"))\n","\n","df_gold_raw = (\n","    df_conformed\n","    .withColumn(\"gold_run_id\", F.lit(gold_run_id))\n","    .withColumn(\"gold_load_ts\", F.current_timestamp())\n",")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"26c40ff8-29ec-4ee2-80b4-6be4576c1519"},{"cell_type":"code","source":["# -----------------------------\n","# 8) Load Gold contract (YAML) + canonical projection + assertions\n","# -----------------------------\n","contract = load_gold_contract(GOLD_TABLE)  # Files/governance/gold/gold_fact_transactions.yaml\n","df_final = project_to_gold_contract(df_gold_raw, contract)\n","\n","apply_gold_contract_assertions(\n","    df=df_final,\n","    contract=contract,\n","    ctx=f\"{ENTITY} (final)\",\n","    enforce_types=True,\n","    enforce_not_null=True,\n","    enforce_unique=True\n",")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"588e7606-a5f1-4488-a8f9-4f33c68cabfe"},{"cell_type":"code","source":["# -----------------------------\n","# 9) Rebuild idempotent (TRUNCATE + APPEND, partitioned)\n","# -----------------------------\n","# partition column must exist in df_final and in the contract (txn_month)\n","rebuild_gold_table(df_final, table_name=GOLD_TABLE, partition_cols=[\"txn_month\"])\n","\n","row_out = df_final.count()\n","partition_count = df_final.select(\"txn_month\").distinct().count()\n","\n","print(f\"Loaded {GOLD_TABLE} successfully. row_out={row_out}, partition_count={partition_count}\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"576fa5e5-9fab-48ed-bb12-c1676035684b"},{"cell_type":"code","source":["# -----------------------------\n","# 10) Exit payload (consumed by dispatcher)\n","# -----------------------------\n","def exit_payload(**kwargs):\n","    payload = {\"status\": \"SUCCESS\", **kwargs}\n","    mssparkutils.notebook.exit(json.dumps(payload, ensure_ascii=False))\n","    \n","exit_payload(\n","    status=\"SUCCESS\",\n","    gold_run_id=gold_run_id,\n","    step_exec_id=step_exec_id,\n","    entity_code=entity_code,\n","    entity=ENTITY,\n","    target_table=GOLD_TABLE,\n","    row_in=row_in,\n","    row_out=row_out,\n","    row_rejected=row_rejected,\n","    dedup_dropped=dedup_dropped,\n","    partition_count=partition_count,\n","    anom_count=anom_count\n",")\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"27ee23a3-e96f-4d52-bedf-dfa75a9b7108"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"86de7d18-06e4-4a37-ac0b-fbd45cf4157a"}],"default_lakehouse":"86de7d18-06e4-4a37-ac0b-fbd45cf4157a","default_lakehouse_name":"lh_wm_core","default_lakehouse_workspace_id":"300f0249-d03f-436c-97fc-5b5940cc3aa3"}}},"nbformat":4,"nbformat_minor":5}